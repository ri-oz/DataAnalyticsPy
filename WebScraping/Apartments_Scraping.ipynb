{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests for handling HTTP get and other requests\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://www.ss.com/lv/real-estate/flats/riga/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get list of all first page urls for all regions\n",
    "def getUrlList(url, prefix='https://www.ss.com', postfix='sell/', tag='a', class_='a_category'):\n",
    "    req = requests.get(url)\n",
    "    if req.status_code != 200:\n",
    "        print(f'Unexpected status code {req.status_code}. Stopping parse')\n",
    "        return [] #return early and often principle\n",
    "    soup = BeautifulSoup(req.text, 'lxml') # could skip soup variable as well but keeping for readability\n",
    "    return [ prefix + el['href'] + postfix for el in soup.find_all(tag, class_) ]\n",
    "    # What else could we pass as argument? How could our return fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRowData(row):\n",
    "    \"\"\"Gets information from  each row\"\"\"\n",
    "    return [el.text for el in row.find_all('td')[2:]] + [baseurl + row.find('a')['href']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDFfromUrl(url, region = None):\n",
    "    print(f'Going to gather data from URL:{url}')\n",
    "    req = requests.get(url)\n",
    "    if req.status_code != 200:\n",
    "        print(f'Unexpected status code {req.status_code}. Stopping parse')\n",
    "        return [] #return early and often principle\n",
    "    soup = BeautifulSoup(req.text, 'lxml') # could skip soup variable as well but keeping for readability\n",
    "    \n",
    "\n",
    "    \n",
    "    headline = soup.find('tr', id = \"head_line\")\n",
    "    cindex = [el.text for el in headline.find_all('td')]\n",
    "    cindex[0] = cindex[0].split()[0]\n",
    "    cindex += ['URL'] #TODO add argument for this\n",
    "    cindex += ['Region']\n",
    "    \n",
    "    # TODO move it somewhere else\n",
    "    if len([el for el in soup.find_all('option') if 'Izīrē' in el.text]) == 0:\n",
    "        print(\"Oops nothing for rent\")\n",
    "        return pd.DataFrame({}, columns=cindex)\n",
    "    \n",
    "    rows = soup.find_all('tr',id = re.compile(r'tr_*'))\n",
    "    rowsdata = [getRowData(el) for el in rows[:-1]]\n",
    "    # finally we add the region if we did not have one\n",
    "    if region == None:\n",
    "        region = url.split(\"/\")[-3]\n",
    "    rowsdata = [el + [region] for el in rowsdata]\n",
    "    return pd.DataFrame(rowsdata, columns=cindex)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with this recipe we can append a big list of dataframes into one\n",
    "def getDFfromUrlList(urlist):\n",
    "    dflist = []\n",
    "    for ur in urlist:\n",
    "        dflist.append(getDFfromUrl(ur))\n",
    "        time.sleep(0.5)\n",
    "    return pd.concat(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRegionUrls(url, optionName = \"Izīrē\"):\n",
    "    regionurls = []\n",
    "    print(f'Going to check Region Url:{url}')\n",
    "    req = requests.get(url)\n",
    "    if req.status_code != 200:\n",
    "        print(f'Unexpected status code {req.status_code}. Stopping parse')\n",
    "        return [] #return early and often principle\n",
    "    soup = BeautifulSoup(req.text, 'lxml') # could skip soup variable as well but keeping for readability\n",
    "    # first we check if the optionName exists at all\n",
    "    hand_options = [el for el in soup.find_all('option') if optionName in el.text]\n",
    "    if len(hand_options) == 0:\n",
    "        return []\n",
    "    \n",
    "    allanchors = soup.find_all('a', {'rel': 'prev'})\n",
    "    if len(allanchors) == 0:\n",
    "        return [url]\n",
    "    \n",
    "    lasturl = allanchors[0]['href']\n",
    "    searchresult = re.search(r'page(\\d+)\\.html', lasturl)\n",
    "    if searchresult:\n",
    "        lastpageNum = int(searchresult.group(1))\n",
    "    else:\n",
    "        print(\"hmm no last page!!\")\n",
    "        return [url]\n",
    "    # we add first page which is just the default url without page num\n",
    "    # following pages have pagenum.html at the end\n",
    "    regionurls =  [url] + [url + \"page\" + str(num) + \".html\" for num in range(2, lastpageNum+1)]\n",
    "    return regionurls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllUrls(urlist):\n",
    "    biglist = []\n",
    "    for url in urlist:\n",
    "        biglist += getRegionUrls(url)\n",
    "        time.sleep(0.5)\n",
    "    return biglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regionUrls = getUrlList(baseurl, postfix=\"hand_over\")\n",
    "len(regionUrls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ss.com/lv/real-estate/flats/riga/vef/hand_over',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/other/hand_over',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/all/hand_over']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regionUrls[-3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to check Region Url:h\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'h': No schema supplied. Perhaps you meant http://h?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d9dc6a0b3388>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mallUrls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAllUrls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregionUrls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mallUrls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-68635d6de035>\u001b[0m in \u001b[0;36mgetAllUrls\u001b[1;34m(urlist)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mbiglist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mbiglist\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgetRegionUrls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbiglist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-414778ab5232>\u001b[0m in \u001b[0;36mgetRegionUrls\u001b[1;34m(url, optionName)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mregionurls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Going to check Region Url:{url}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Unexpected status code {req.status_code}. Stopping parse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         )\n\u001b[1;32m--> 519\u001b[1;33m         \u001b[0mprep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m         )\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingSchema\u001b[0m: Invalid URL 'h': No schema supplied. Perhaps you meant http://h?"
     ]
    }
   ],
   "source": [
    "allUrls = getAllUrls(regionUrls[-1])\n",
    "allUrls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ss.com/lv/real-estate/flats/riga/all/hand_over'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regionUrls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to check Region Url:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/\n"
     ]
    }
   ],
   "source": [
    "allriga = getRegionUrls('https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allriga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page2.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page3.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page4.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page5.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page6.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page7.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page8.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page9.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page10.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page11.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page12.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page13.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page14.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page15.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page16.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page17.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page18.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page19.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page20.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page21.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page22.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page23.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page24.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page25.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page26.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page27.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page28.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page29.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page30.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page31.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page32.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page33.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page34.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page35.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page36.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page37.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page38.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page39.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page40.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page41.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page42.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page43.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page44.html\n",
      "Going to gather data from URL:https://www.ss.com/lv/real-estate/flats/riga/all/hand_over/page45.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1331, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rigadf = getDFfromUrlList(allriga)\n",
    "rigadf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigadf.to_excel('RigaApartments.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
